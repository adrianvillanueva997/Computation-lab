import pandas as pd
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer
from sklearn.model_selection import train_test_split
from proyecto_1 import Text_Procesing


class Vectorizer:
    """
    Class that does all the vectorization and generation process of the whole data frame and the test/train slitted data
    """

    def __init__(self, g_reviews, b_reviews, n_reviews):
        """
        Class constructor
        """
        self.__data_frame = pd.DataFrame()
        self.__g_reviews = g_reviews
        self.__b_reviews = b_reviews
        self.__n_reviews = n_reviews

    def __generate_dataframe(self):
        """
        Generates and returns a data frame given the previously preprocessed reviews
        :param g_reviews:
        :param b_reviews:
        :param n_reviews:
        """
        data = {
            'reviews': [],
            'labels': []
        }

        for review in self.__g_reviews:
            data['reviews'].append(review)
            data['labels'].append(1)

        for review in self.__b_reviews:
            data['reviews'].append(review)
            data['labels'].append(2)

        for review in self.__n_reviews:
            data['reviews'].append(review)
            data['labels'].append(3)

        self.__data_frame = pd.DataFrame(data)

    @staticmethod
    def __count_vectorizer(x_train, x_test, to_array=False):
        """
        Convert a collection of text documents to a matrix of token counts
        :param to_array:
        """
        tp = Text_Procesing.Text_Processing()
        stop_words = set(stopwords.words('spanish'))
        cv = CountVectorizer(tokenizer=tp.tokenizer, stop_words=stop_words)
        cv.fit(x_train)
        if to_array:
            x_train = cv.transform(x_train).toarray()
            x_test = cv.transform(x_test).toarray()
            return x_train, x_test
        else:
            x_train = cv.transform(x_train)
            x_test = cv.transform(x_test)
            return x_train, x_test

    @staticmethod
    def __term_frequency_vectorizer(x_train, x_test, to_array=False):
        """
        Convert a collection of text documents to a matrix of token occurrences
        :param to_array:
        """
        tp = Text_Procesing.Text_Processing()
        stop_words = set(stopwords.words('spanish'))
        tf = TfidfVectorizer(tokenizer=tp.tokenizer, stop_words=stop_words)
        tf.fit(x_train)
        if to_array:
            x_train = tf.transform(x_train).toarray()
            x_test = tf.transform(x_test).toarray()
            return x_train, x_test
        else:
            x_train = tf.transform(x_train)
            x_test = tf.transform(x_test)
            return x_train, x_test

    def generate_train_test_data(self, vectorizer, to_array=False, test_size=0.1, random_state=None,
                                 train_size=None):
        """
        Generate train/test data given some vectorized reviews
        :param train_size: represent the proportion of the dataset to include in the test split. (if float, it should be between 0 and 1)
        :param test_size: represent the proportion of the dataset to include in the train split. (if float, it should be between 0 and 1)
        :param random_state: seed used by the random number generator. If it's none it is generated by numpy
        :return: X_train, X_test, y_train, y_test
        """
        self.__generate_dataframe()
        x_train, x_test, y_train, y_test = train_test_split(self.__data_frame['reviews'],
                                                            self.__data_frame['labels'],
                                                            test_size=test_size,
                                                            random_state=random_state,
                                                            train_size=train_size)
        if vectorizer == "count_vect":
            x_train, x_test = self.__count_vectorizer(x_train=x_train, x_test=x_test, to_array=to_array)
        elif vectorizer == "tfid":
            x_train, x_test = self.__term_frequency_vectorizer(x_train=x_train, x_test=x_test, to_array=to_array)

        else:
            return None

        return x_train, x_test, y_train, y_test
