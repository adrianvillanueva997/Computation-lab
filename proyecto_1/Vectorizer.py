import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer
from sklearn.model_selection import train_test_split


class Vectorizer:
    """
    Class that does all the vectorization and generation process of the whole data frame and the test/train slitted data
    """

    def __init__(self):
        """
        Class constructor
        """
        self.dataframe = pd.DataFrame()

    def generate_dataframe(self, g_reviews, b_reviews, n_reviews):
        """
        Generates and returns a data frame given the previously preprocessed reviews
        :param g_reviews:
        :param b_reviews:
        :param n_reviews:
        :return: dataframe
        """
        data = {
            'reviews': [],
            'labels': []
        }

        for review in g_reviews:
            data['reviews'].append(review)
            data['labels'].append(1)

        for review in b_reviews:
            data['reviews'].append(review)
            data['labels'].append(2)

        for review in n_reviews:
            data['reviews'].append(review)
            data['labels'].append(3)

        dataframe = pd.DataFrame(data)
        self.dataframe = dataframe
        return dataframe

    @staticmethod
    def count_vectorizer(dataframe):
        """
        Convert a collection of text documents to a matrix of token counts
        :return:
        :param dataframe:
        :return:vectorized_reviews
        """
        cv = CountVectorizer()
        vectorized_reviews = cv.fit_transform(dataframe['reviews'])
        return vectorized_reviews

    @staticmethod
    def term_frequency_vectorizer(dataframe):
        """
        Convert a collection of text documents to a matrix of token occurrences
        :param dataframe:
        :return: vectorized_reviews
        """
        tf = TfidfVectorizer()
        vectorized_reviews = tf.fit_transform(dataframe['reviews'])
        return vectorized_reviews

    @staticmethod
    def hash_vectorizer(dataframe):
        """
        Convert a collection of raw documents to a matrix of TF-IDF features.
        :param dataframe:
        :return:vectorized_reviews
        """
        hs = HashingVectorizer()
        vectorized_reviews = hs.fit_transform(dataframe['reviews'])
        return vectorized_reviews

    def generate_train_test_data(self, vectorized_reviews, test_size=0.1, random_state=None,
                                 train_size=None):
        """
        Generate train/test data given some vectorized reviews
        test_size: represent the proportion of the dataset to include in the test split. (if float, it should be between 0 and 1)
        train_size: represent the proportion of the dataset to include in the train split. (if float, it should be between 0 and 1)
        random_state: seed used by the random number generator. If it's none it is generated by numpy
        :param vectorized_reviews:
        :param test_size:
        :param random_state:
        :return: X_train, X_test, y_train, y_test
        """
        X_train, X_test, y_train, y_test = train_test_split(vectorized_reviews, self.dataframe['labels'],
                                                            test_size=test_size,
                                                            random_state=random_state,
                                                            train_size=train_size)

        return X_train, X_test, y_train, y_test
